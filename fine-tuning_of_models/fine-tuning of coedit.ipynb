{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('grammarly/coedit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Define constants\n",
    "model_id = \"t5-small\"\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "# Load the T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_data(examples):\n",
    "    inputs = [sentence for sentence in examples['src']]\n",
    "    targets = [sentence for sentence in examples['tgt']]\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_LENGTH, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=MAX_LENGTH, truncation=True, padding=\"max_length\").input_ids\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25902' max='25902' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25902/25902 1:23:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.168600</td>\n",
       "      <td>0.245516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158300</td>\n",
       "      <td>0.234669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.232516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25902, training_loss=0.19142372173173539, metrics={'train_runtime': 4999.5952, 'train_samples_per_second': 41.446, 'train_steps_per_second': 5.181, 'total_flos': 7011145177104384.0, 'train_loss': 0.19142372173173539, 'epoch': 3.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Load the T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_id)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation']\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (4.42.3)\n",
      "Requirement already satisfied: filelock in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (4.66.4)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: torch in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from transformers[torch]) (2.3.1+cu118)\n",
      "Requirement already satisfied: psutil in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from torch->transformers[torch]) (11.8.86)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from requests->transformers[torch]) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/shreeyutm/anaconda3/envs/py312/lib/python3.12/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.33.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gennie/tokenizer_config.json',\n",
       " 'gennie/special_tokens_map.json',\n",
       " 'gennie/spiece.model',\n",
       " 'gennie/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('gennie')\n",
    "tokenizer.save_pretrained('gennie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/shreeyutm/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual token\n",
    "login(token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69dd1f95f3e403c979409fae54b37f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8480043d3847495c8f487c982979a171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1721845277.LAPTOP-N36F6CKI.6531.0:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbda5ecb067345d5a104c75bdcca7601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574d0fe1efb848c2a16a5dcd62c23dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Shreeyut/results/commit/201e12692a2e0128c71e81e2bd070b034e2a0acb', commit_message='End of training', commit_description='', oid='201e12692a2e0128c71e81e2bd070b034e2a0acb', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
